{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils.vis_utils import plot_model\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No NaN values found.\n"
     ]
    }
   ],
   "source": [
    "# Load the data from CSV file\n",
    "df = pd.read_csv(\"bankruptcy.csv\")\n",
    "# df.head()\n",
    "\n",
    "# Check for NaN Values\n",
    "nan_rows = df[df.isna().any(axis=1)]\n",
    "if len(nan_rows) > 0:\n",
    "    print(nan_rows)\n",
    "else:\n",
    "    print(\"No NaN values found.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will split the data into two different groups. The first dataframe will contain all 95 variables while the second dataframe will contain the top 10 variables with the highest correlation to bankruptcy. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below is for all variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets for all variables\n",
    "X = df.drop(\"Bankrupt?\", axis=1)\n",
    "y = df[\"Bankrupt?\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=42)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below is for the top 10 variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets for top 10 variables based on correlation with bankruptcy\n",
    "\n",
    "corr_matrix = df.corr()\n",
    "num_features = 10\n",
    "corr_with_bankrupt = corr_matrix[\"Bankrupt?\"].abs().sort_values(ascending=False)\n",
    "top_corr_features = corr_with_bankrupt[1:num_features+1].index.tolist()\n",
    "df_top10 = df[top_corr_features]\n",
    "X_top10 = df_top10\n",
    "y_top10 = df[\"Bankrupt?\"]\n",
    "X_train_top10, X_test_top10, y_train_top10, y_test_top10 = train_test_split(X_top10, y_top10, test_size=0.2,random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a Neural Network Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code creates a neural network model using the Keras library with two layers. The first layer is a fully connected (Dense) layer with 64 neurons, which takes an input of shape X_train.shape[1] (the number of features in the training data) and uses the ReLU activation function. The second layer is another Dense layer with a single neuron and uses the sigmoid activation function, which is commonly used for binary classification problems.\n",
    "\n",
    "In summary, the model has an input layer with the same number of neurons as the number of features in the data, one hidden layer with 64 neurons, and an output layer with a single neuron that outputs a probability between 0 and 1 representing the likelihood of the input belonging to the positive class (bankruptcy in this case)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the neural network model\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "# Visualize the model\n",
    "# plot_model(model, to_file='model.png', show_shapes=True)\n",
    "\n",
    "model_top10 = Sequential()\n",
    "model_top10.add(Dense(64, input_dim=X_train_top10.shape[1], activation='relu'))\n",
    "model_top10.add(Dense(32, activation='relu'))\n",
    "model_top10.add(Dense(32, activation='relu'))\n",
    "model_top10.add(Dense(32, activation='relu'))\n",
    "model_top10.add(Dense(32, activation='relu'))\n",
    "model_top10.add(Dense(1, activation='sigmoid'))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model.compile is a function in Keras that compiles the model with the chosen loss function, optimizer, and metrics. In this case, the loss function chosen is binary_crossentropy, which is commonly used for binary classification problems. The optimizer chosen is adam, which is a commonly used optimization algorithm for neural networks. Finally, metrics is set to accuracy, which will be used to evaluate the performance of the model during training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model for all variables\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Compile the model for top 10 variables\n",
    "model_top10.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This line of code trains the neural network model on the training data with the following parameters:\n",
    "\n",
    "X_train and y_train: the input features and corresponding target variable used for training the model.\n",
    "epochs=50: the number of times the model is trained on the entire training dataset.\n",
    "batch_size=32: the number of samples that will be used in each batch of training.\n",
    "validation_data=(X_test, y_test): the validation data on which the model will be evaluated after each epoch of training. The validation data is used to monitor the performance of the model on data that it has not seen during training.\n",
    "During training, the model tries to minimize the binary cross-entropy loss function using the Adam optimizer. The accuracy metric is also computed during training to evaluate the performance of the model on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "171/171 [==============================] - 2s 3ms/step - loss: 2052810.8750 - accuracy: 0.9437 - val_loss: 1088040.8750 - val_accuracy: 0.9604\n",
      "Epoch 2/50\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 620240.0000 - accuracy: 0.9463 - val_loss: 734833.0625 - val_accuracy: 0.9128\n",
      "Epoch 3/50\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 474327.9688 - accuracy: 0.9443 - val_loss: 722236.9375 - val_accuracy: 0.9567\n",
      "Epoch 4/50\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 328746.1250 - accuracy: 0.9467 - val_loss: 424546.8750 - val_accuracy: 0.9428\n",
      "Epoch 5/50\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 240331.9375 - accuracy: 0.9468 - val_loss: 351104.8438 - val_accuracy: 0.9435\n",
      "Epoch 6/50\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 216545.8906 - accuracy: 0.9439 - val_loss: 340141.2188 - val_accuracy: 0.9362\n",
      "Epoch 7/50\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 179240.9688 - accuracy: 0.9452 - val_loss: 329829.2188 - val_accuracy: 0.9304\n",
      "Epoch 8/50\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 151742.0000 - accuracy: 0.9441 - val_loss: 265400.5000 - val_accuracy: 0.9289\n",
      "Epoch 9/50\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 110621.6094 - accuracy: 0.9430 - val_loss: 279640.9375 - val_accuracy: 0.9494\n",
      "Epoch 10/50\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 105298.8906 - accuracy: 0.9454 - val_loss: 233047.4531 - val_accuracy: 0.9443\n",
      "Epoch 11/50\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 112747.3516 - accuracy: 0.9424 - val_loss: 250698.1875 - val_accuracy: 0.9479\n",
      "Epoch 12/50\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 79033.5469 - accuracy: 0.9452 - val_loss: 207391.8125 - val_accuracy: 0.9413\n",
      "Epoch 13/50\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 69904.1797 - accuracy: 0.9476 - val_loss: 202378.1406 - val_accuracy: 0.9567\n",
      "Epoch 14/50\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 67476.1250 - accuracy: 0.9435 - val_loss: 148319.6406 - val_accuracy: 0.9509\n",
      "Epoch 15/50\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 63799.6758 - accuracy: 0.9446 - val_loss: 150475.2031 - val_accuracy: 0.9091\n",
      "Epoch 16/50\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 41475.1562 - accuracy: 0.9485 - val_loss: 219479.2500 - val_accuracy: 0.9523\n",
      "Epoch 17/50\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 54367.1328 - accuracy: 0.9450 - val_loss: 155615.2031 - val_accuracy: 0.9567\n",
      "Epoch 18/50\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 81671.2109 - accuracy: 0.9441 - val_loss: 142943.4375 - val_accuracy: 0.9076\n",
      "Epoch 19/50\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 36230.8477 - accuracy: 0.9437 - val_loss: 201634.9531 - val_accuracy: 0.9626\n",
      "Epoch 20/50\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 35251.9805 - accuracy: 0.9463 - val_loss: 165993.9062 - val_accuracy: 0.9479\n",
      "Epoch 21/50\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 28682.1113 - accuracy: 0.9468 - val_loss: 176311.8438 - val_accuracy: 0.8871\n",
      "Epoch 22/50\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 23162.7148 - accuracy: 0.9382 - val_loss: 199447.3125 - val_accuracy: 0.9611\n",
      "Epoch 23/50\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 10869.9502 - accuracy: 0.9489 - val_loss: 239709.4844 - val_accuracy: 0.6664\n",
      "Epoch 24/50\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 15471.4980 - accuracy: 0.9410 - val_loss: 247966.4531 - val_accuracy: 0.9619\n",
      "Epoch 25/50\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 19527.1738 - accuracy: 0.9406 - val_loss: 243485.6094 - val_accuracy: 0.9611\n",
      "Epoch 26/50\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 9920.2900 - accuracy: 0.9443 - val_loss: 263357.8750 - val_accuracy: 0.7742\n",
      "Epoch 27/50\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 10385.7061 - accuracy: 0.9384 - val_loss: 287840.1875 - val_accuracy: 0.9575\n",
      "Epoch 28/50\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 11925.2119 - accuracy: 0.9421 - val_loss: 227377.5469 - val_accuracy: 0.9619\n",
      "Epoch 29/50\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 10406.8770 - accuracy: 0.9456 - val_loss: 227356.5000 - val_accuracy: 0.9619\n",
      "Epoch 30/50\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 7122.2549 - accuracy: 0.9423 - val_loss: 239078.6094 - val_accuracy: 0.9589\n",
      "Epoch 31/50\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 11097.0586 - accuracy: 0.9443 - val_loss: 219228.2656 - val_accuracy: 0.9435\n",
      "Epoch 32/50\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 11000.1006 - accuracy: 0.9441 - val_loss: 151141.7969 - val_accuracy: 0.9604\n",
      "Epoch 33/50\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 11399.6934 - accuracy: 0.9408 - val_loss: 366730.6250 - val_accuracy: 0.8893\n",
      "Epoch 34/50\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 5603.8892 - accuracy: 0.9377 - val_loss: 421208.3125 - val_accuracy: 0.9626\n",
      "Epoch 35/50\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 3027.4121 - accuracy: 0.9468 - val_loss: 476249.8125 - val_accuracy: 0.9619\n",
      "Epoch 36/50\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 14476.1680 - accuracy: 0.9505 - val_loss: 357150.4375 - val_accuracy: 0.9582\n",
      "Epoch 37/50\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 2735.3130 - accuracy: 0.9604 - val_loss: 367907.9062 - val_accuracy: 0.9560\n",
      "Epoch 38/50\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 473.7487 - accuracy: 0.9571 - val_loss: 390644.5938 - val_accuracy: 0.9164\n",
      "Epoch 39/50\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 323.0574 - accuracy: 0.9615 - val_loss: 428858.1250 - val_accuracy: 0.9611\n",
      "Epoch 40/50\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 2018.6862 - accuracy: 0.9639 - val_loss: 307525.9688 - val_accuracy: 0.9626\n",
      "Epoch 41/50\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 626.9752 - accuracy: 0.9646 - val_loss: 379411.9062 - val_accuracy: 0.9377\n",
      "Epoch 42/50\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 1426.3799 - accuracy: 0.9650 - val_loss: 374805.4062 - val_accuracy: 0.9619\n",
      "Epoch 43/50\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 433.4776 - accuracy: 0.9663 - val_loss: 363299.7500 - val_accuracy: 0.9619\n",
      "Epoch 44/50\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 402.8585 - accuracy: 0.9681 - val_loss: 214403.2188 - val_accuracy: 0.9604\n",
      "Epoch 45/50\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 2812.2720 - accuracy: 0.9628 - val_loss: 166495.2656 - val_accuracy: 0.9611\n",
      "Epoch 46/50\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 300.4631 - accuracy: 0.9599 - val_loss: 197099.6562 - val_accuracy: 0.9604\n",
      "Epoch 47/50\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 4373.1885 - accuracy: 0.9615 - val_loss: 240074.6250 - val_accuracy: 0.9611\n",
      "Epoch 48/50\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 495.6588 - accuracy: 0.9668 - val_loss: 93689.8906 - val_accuracy: 0.9626\n",
      "Epoch 49/50\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 1212.8860 - accuracy: 0.9650 - val_loss: 61561.9766 - val_accuracy: 0.9428\n",
      "Epoch 50/50\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 153.1957 - accuracy: 0.9668 - val_loss: 66126.3203 - val_accuracy: 0.9619\n",
      "Epoch 1/50\n",
      "171/171 [==============================] - 1s 2ms/step - loss: 0.2063 - accuracy: 0.9688 - val_loss: 0.1459 - val_accuracy: 0.9626\n",
      "Epoch 2/50\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 0.1255 - accuracy: 0.9690 - val_loss: 0.1396 - val_accuracy: 0.9626\n",
      "Epoch 3/50\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 0.1182 - accuracy: 0.9690 - val_loss: 0.1249 - val_accuracy: 0.9626\n",
      "Epoch 4/50\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 0.1045 - accuracy: 0.9690 - val_loss: 0.1058 - val_accuracy: 0.9648\n",
      "Epoch 5/50\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 0.0964 - accuracy: 0.9701 - val_loss: 0.1009 - val_accuracy: 0.9655\n",
      "Epoch 6/50\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 0.0956 - accuracy: 0.9698 - val_loss: 0.1155 - val_accuracy: 0.9648\n",
      "Epoch 7/50\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 0.0944 - accuracy: 0.9709 - val_loss: 0.1010 - val_accuracy: 0.9663\n",
      "Epoch 8/50\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 0.0921 - accuracy: 0.9699 - val_loss: 0.1003 - val_accuracy: 0.9655\n",
      "Epoch 9/50\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 0.0932 - accuracy: 0.9701 - val_loss: 0.1039 - val_accuracy: 0.9655\n",
      "Epoch 10/50\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 0.0922 - accuracy: 0.9707 - val_loss: 0.1073 - val_accuracy: 0.9655\n",
      "Epoch 11/50\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 0.0916 - accuracy: 0.9703 - val_loss: 0.0999 - val_accuracy: 0.9663\n",
      "Epoch 12/50\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 0.0914 - accuracy: 0.9699 - val_loss: 0.1032 - val_accuracy: 0.9655\n",
      "Epoch 13/50\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 0.0911 - accuracy: 0.9703 - val_loss: 0.1014 - val_accuracy: 0.9655\n",
      "Epoch 14/50\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 0.0915 - accuracy: 0.9701 - val_loss: 0.1085 - val_accuracy: 0.9641\n",
      "Epoch 15/50\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 0.0923 - accuracy: 0.9709 - val_loss: 0.1179 - val_accuracy: 0.9641\n",
      "Epoch 16/50\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 0.0928 - accuracy: 0.9709 - val_loss: 0.1004 - val_accuracy: 0.9655\n",
      "Epoch 17/50\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 0.0901 - accuracy: 0.9709 - val_loss: 0.1008 - val_accuracy: 0.9648\n",
      "Epoch 18/50\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 0.0906 - accuracy: 0.9701 - val_loss: 0.1031 - val_accuracy: 0.9655\n",
      "Epoch 19/50\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 0.0943 - accuracy: 0.9705 - val_loss: 0.1034 - val_accuracy: 0.9663\n",
      "Epoch 20/50\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 0.0916 - accuracy: 0.9707 - val_loss: 0.0998 - val_accuracy: 0.9655\n",
      "Epoch 21/50\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 0.0916 - accuracy: 0.9709 - val_loss: 0.0999 - val_accuracy: 0.9663\n",
      "Epoch 22/50\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 0.0910 - accuracy: 0.9709 - val_loss: 0.1004 - val_accuracy: 0.9663\n",
      "Epoch 23/50\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 0.0898 - accuracy: 0.9709 - val_loss: 0.0995 - val_accuracy: 0.9663\n",
      "Epoch 24/50\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 0.0917 - accuracy: 0.9709 - val_loss: 0.1002 - val_accuracy: 0.9655\n",
      "Epoch 25/50\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 0.0903 - accuracy: 0.9710 - val_loss: 0.1001 - val_accuracy: 0.9655\n",
      "Epoch 26/50\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 0.0892 - accuracy: 0.9709 - val_loss: 0.1110 - val_accuracy: 0.9641\n",
      "Epoch 27/50\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 0.0940 - accuracy: 0.9701 - val_loss: 0.1030 - val_accuracy: 0.9641\n",
      "Epoch 28/50\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 0.0914 - accuracy: 0.9707 - val_loss: 0.1037 - val_accuracy: 0.9648\n",
      "Epoch 29/50\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 0.0926 - accuracy: 0.9705 - val_loss: 0.1117 - val_accuracy: 0.9655\n",
      "Epoch 30/50\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 0.0898 - accuracy: 0.9710 - val_loss: 0.1009 - val_accuracy: 0.9655\n",
      "Epoch 31/50\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 0.0897 - accuracy: 0.9712 - val_loss: 0.1014 - val_accuracy: 0.9641\n",
      "Epoch 32/50\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 0.0906 - accuracy: 0.9703 - val_loss: 0.1001 - val_accuracy: 0.9655\n",
      "Epoch 33/50\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 0.0915 - accuracy: 0.9705 - val_loss: 0.0993 - val_accuracy: 0.9670\n",
      "Epoch 34/50\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 0.0898 - accuracy: 0.9707 - val_loss: 0.1021 - val_accuracy: 0.9663\n",
      "Epoch 35/50\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 0.0902 - accuracy: 0.9703 - val_loss: 0.1005 - val_accuracy: 0.9663\n",
      "Epoch 36/50\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 0.0905 - accuracy: 0.9710 - val_loss: 0.1031 - val_accuracy: 0.9655\n",
      "Epoch 37/50\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 0.0900 - accuracy: 0.9710 - val_loss: 0.1003 - val_accuracy: 0.9655\n",
      "Epoch 38/50\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 0.0907 - accuracy: 0.9710 - val_loss: 0.1003 - val_accuracy: 0.9655\n",
      "Epoch 39/50\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 0.0922 - accuracy: 0.9709 - val_loss: 0.1003 - val_accuracy: 0.9663\n",
      "Epoch 40/50\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 0.0896 - accuracy: 0.9710 - val_loss: 0.1009 - val_accuracy: 0.9655\n",
      "Epoch 41/50\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 0.0889 - accuracy: 0.9709 - val_loss: 0.1019 - val_accuracy: 0.9663\n",
      "Epoch 42/50\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 0.0895 - accuracy: 0.9707 - val_loss: 0.1007 - val_accuracy: 0.9641\n",
      "Epoch 43/50\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 0.0884 - accuracy: 0.9710 - val_loss: 0.1060 - val_accuracy: 0.9663\n",
      "Epoch 44/50\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 0.0917 - accuracy: 0.9709 - val_loss: 0.1000 - val_accuracy: 0.9655\n",
      "Epoch 45/50\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 0.0893 - accuracy: 0.9709 - val_loss: 0.1010 - val_accuracy: 0.9648\n",
      "Epoch 46/50\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 0.0894 - accuracy: 0.9705 - val_loss: 0.0995 - val_accuracy: 0.9663\n",
      "Epoch 47/50\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 0.0891 - accuracy: 0.9712 - val_loss: 0.1009 - val_accuracy: 0.9655\n",
      "Epoch 48/50\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 0.0894 - accuracy: 0.9710 - val_loss: 0.1011 - val_accuracy: 0.9655\n",
      "Epoch 49/50\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 0.0891 - accuracy: 0.9712 - val_loss: 0.1000 - val_accuracy: 0.9663\n",
      "Epoch 50/50\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 0.0886 - accuracy: 0.9710 - val_loss: 0.1005 - val_accuracy: 0.9655\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1435c0ac0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model for all variables\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Train the model for top 10 variables\n",
    "\n",
    "model_top10.fit(X_train_top10, y_train_top10, epochs=50, batch_size=32, validation_data=(X_test_top10, y_test_top10))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seeing the accuracy of our NN model(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 0s 890us/step - loss: 66126.3203 - accuracy: 0.9619\n",
      "Accuracy for dataset with all variables: 0.9618768095970154\n",
      "43/43 [==============================] - 0s 901us/step - loss: 0.1005 - accuracy: 0.9655\n",
      "Accuracy for dataset with top 10 variables: 0.9655424952507019\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test data\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "\n",
    "# Print the accuracy\n",
    "print(\"Accuracy for dataset with all variables:\", accuracy)\n",
    "\n",
    "loss_top10, accuracy_top10 = model_top10.evaluate(X_test_top10, y_test_top10)\n",
    "\n",
    "print(\"Accuracy for dataset with top 10 variables:\", accuracy_top10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying to do some visualisation of the data here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a correlation matrix\n",
    "corr_matrix = df.corr()\n",
    "\n",
    "# Generate a heatmap using seaborn\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr_matrix, cmap='coolwarm')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(df.columns.to_list)\n",
    "\n",
    "bankrupt_df = df[['Bankrupt?', ' Cash Flow to Sales']]\n",
    "bankrupt_corr_matrix = bankrupt_df.corr()\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(bankrupt_corr_matrix, cmap='coolwarm', annot = True)\n",
    "plt.title('Correlation with Bankrupt?')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the top 10 features with highest absolute correlation values with Bankrupt? column\n",
    "num_features = 10\n",
    "corr_with_bankrupt = corr_matrix[\"Bankrupt?\"].abs().sort_values(ascending=False)\n",
    "top_corr_features = corr_with_bankrupt[1:num_features+1].index.tolist()\n",
    "\n",
    "# Create a heatmap of top 10 features with highest absolute correlation values\n",
    "sns.set(style=\"white\")\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(df[top_corr_features].corr(), annot=True, cmap=\"YlGnBu\")\n",
    "plt.title(\"Top 10 features with highest absolute correlation values with Bankrupt and their respective correlations with one another\", fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in top_corr_features:\n",
    "    sns.violinplot(data=df[feature], orient = \"h\")\n",
    "    plt.title(feature)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in top_corr_features:\n",
    "    sns.boxplot(data = df[feature], orient = \"h\")\n",
    "    plt.title(feature)\n",
    "    q1, q3 = df[feature].quantile([0.25, 0.75])\n",
    "    iqr = q3 - q1\n",
    "\n",
    "    # Identify the lower and upper bounds\n",
    "    lower_bound = q1 - (1.5 * iqr)\n",
    "    upper_bound = q3 + (1.5 * iqr)\n",
    "\n",
    "    # Count the number of outliers\n",
    "    outliers = len(df[(df[feature] < lower_bound) | (df[feature] > upper_bound)])\n",
    "\n",
    "    print(f\"Number of Outliers for{feature}:\", outliers)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create scatter plot for each combination of top features\n",
    "# for i in range(len(top_corr_features)):\n",
    "#     for j in range(i+1, len(top_corr_features)):\n",
    "#         feature1 = top_corr_features[i]\n",
    "#         feature2 = top_corr_features[j]\n",
    "#         sns.jointplot(x=feature1, y=feature2, data=df, kind='reg')\n",
    "#         plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a Decision Tree Model\n",
    "\n",
    "This code trains a decision tree classifier model dectree with a maximum depth of 2 on the training data X_train and y_train.\n",
    "\n",
    "After training, the model is visualized as a tree using the plot_tree function from sklearn.tree. The plot_tree function generates a tree diagram that shows the decision-making process of the decision tree model.\n",
    "\n",
    "The filled=True argument fills the tree nodes with colors to indicate the class distribution, while the rounded=True argument makes the edges of the boxes around the nodes rounded.\n",
    "\n",
    "The feature_names argument specifies the names of the input features or predictors, which are columns in the DataFrame X.\n",
    "\n",
    "The class_names argument specifies the names of the target classes or outputs, which in this case are \"Not Bankrupt\" and \"Bankrupt\".\n",
    "\n",
    "The resulting tree diagram can be used to interpret how the model makes predictions for new data based on the values of the input features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dectree = DecisionTreeClassifier(max_depth=2)\n",
    "dectree.fit(X_train, y_train)\n",
    "\n",
    "f = plt.figure(figsize=(24,24))\n",
    "plot_tree(dectree, filled=True, rounded=True, \n",
    "          feature_names=X.columns, \n",
    "          class_names=[\"Not Bankrupt\",\"Bankrupt\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seeing the accuracy of our Decision Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the accuracy of the model\n",
    "y_pred = dectree.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy of the model: {:.2f}%\".format(accuracy*100))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "397704579725e15f5c7cb49fe5f0341eb7531c82d19f2c29d197e8b64ab5776b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
