{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: jupyter 1.0.0\r\n",
      "Uninstalling jupyter-1.0.0:\r\n",
      "  Would remove:\r\n",
      "    /Users/jingxuan/anaconda3/lib/python3.10/site-packages/jupyter-1.0.0.dist-info/*\r\n",
      "    /Users/jingxuan/anaconda3/lib/python3.10/site-packages/jupyter.py\r\n",
      "Proceed (Y/n)? "
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip uninstall jupyter\n",
    "!{sys.executable} -m pip install jupyter\n",
    "!{sys.executable} -m pip install keras\n",
    "!{sys.executable} -m pip install tensorflow\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data from CSV file\n",
    "df = pd.read_csv(\"bankruptcy.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X = df.drop(\"Bankrupt?\", axis=1)\n",
    "y = df[\"Bankrupt?\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a Neural Network Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code creates a neural network model using the Keras library with two layers. The first layer is a fully connected (Dense) layer with 64 neurons, which takes an input of shape X_train.shape[1] (the number of features in the training data) and uses the ReLU activation function. The second layer is another Dense layer with a single neuron and uses the sigmoid activation function, which is commonly used for binary classification problems.\n",
    "\n",
    "In summary, the model has an input layer with the same number of neurons as the number of features in the data, one hidden layer with 64 neurons, and an output layer with a single neuron that outputs a probability between 0 and 1 representing the likelihood of the input belonging to the positive class (bankruptcy in this case)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the neural network model\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model.compile is a function in Keras that compiles the model with the chosen loss function, optimizer, and metrics. In this case, the loss function chosen is binary_crossentropy, which is commonly used for binary classification problems. The optimizer chosen is adam, which is a commonly used optimization algorithm for neural networks. Finally, metrics is set to accuracy, which will be used to evaluate the performance of the model during training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This line of code trains the neural network model on the training data with the following parameters:\n",
    "\n",
    "X_train and y_train: the input features and corresponding target variable used for training the model.\n",
    "epochs=50: the number of times the model is trained on the entire training dataset.\n",
    "batch_size=32: the number of samples that will be used in each batch of training.\n",
    "validation_data=(X_test, y_test): the validation data on which the model will be evaluated after each epoch of training. The validation data is used to monitor the performance of the model on data that it has not seen during training.\n",
    "During training, the model tries to minimize the binary cross-entropy loss function using the Adam optimizer. The accuracy metric is also computed during training to evaluate the performance of the model on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seeing the accuracy of our CNN model(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test data\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "\n",
    "# Print the accuracy\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying to do some visualisation of the data here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a correlation matrix\n",
    "corr_matrix = df.corr()\n",
    "\n",
    "# Generate a heatmap using seaborn\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr_matrix, cmap='coolwarm')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the top 10 features with highest absolute correlation values with Bankrupt? column\n",
    "num_features = 10\n",
    "corr_with_bankrupt = corr_matrix[\"Bankrupt?\"].abs().sort_values(ascending=False)\n",
    "top_corr_features = corr_with_bankrupt[1:num_features+1].index.tolist()\n",
    "\n",
    "# Create a heatmap of top 10 features with highest absolute correlation values\n",
    "sns.set(style=\"white\")\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(df[top_corr_features].corr(), annot=True, cmap=\"YlGnBu\")\n",
    "plt.title(\"Top 10 features with highest absolute correlation values with Bankrupt and their respective correlations with one another\", fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create scatter plot for each combination of top features\n",
    "# for i in range(len(top_corr_features)):\n",
    "#     for j in range(i+1, len(top_corr_features)):\n",
    "#         feature1 = top_corr_features[i]\n",
    "#         feature2 = top_corr_features[j]\n",
    "#         sns.jointplot(x=feature1, y=feature2, data=df, kind='reg')\n",
    "#         plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a Decision Tree Model\n",
    "\n",
    "This code trains a decision tree classifier model dectree with a maximum depth of 2 on the training data X_train and y_train.\n",
    "\n",
    "After training, the model is visualized as a tree using the plot_tree function from sklearn.tree. The plot_tree function generates a tree diagram that shows the decision-making process of the decision tree model.\n",
    "\n",
    "The filled=True argument fills the tree nodes with colors to indicate the class distribution, while the rounded=True argument makes the edges of the boxes around the nodes rounded.\n",
    "\n",
    "The feature_names argument specifies the names of the input features or predictors, which are columns in the DataFrame X.\n",
    "\n",
    "The class_names argument specifies the names of the target classes or outputs, which in this case are \"Not Bankrupt\" and \"Bankrupt\".\n",
    "\n",
    "The resulting tree diagram can be used to interpret how the model makes predictions for new data based on the values of the input features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dectree = DecisionTreeClassifier(max_depth=2)\n",
    "dectree.fit(X_train, y_train)\n",
    "\n",
    "f = plt.figure(figsize=(24,24))\n",
    "plot_tree(dectree, filled=True, rounded=True, \n",
    "          feature_names=X.columns, \n",
    "          class_names=[\"Not Bankrupt\",\"Bankrupt\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seeing the accuracy of our Decision Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the accuracy of the model\n",
    "y_pred = dectree.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy of the model: {:.2f}%\".format(accuracy*100))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "397704579725e15f5c7cb49fe5f0341eb7531c82d19f2c29d197e8b64ab5776b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
